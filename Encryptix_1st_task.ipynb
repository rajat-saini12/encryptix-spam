{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee447b6d-d562-492a-94f8-666f8b13c3b6",
   "metadata": {},
   "source": [
    "# imported libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "526e7015-a565-465d-be91-b7fc72521186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "import re\n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cbf4f7-4988-4656-aa01-eb7b2f040b5b",
   "metadata": {},
   "source": [
    "# load specific datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7ffce62-089d-4a8b-a954-d0b11bfde2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"d:/dataset/dataset/spam.csv\", encoding='latin1')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1c6064-f7e0-40ad-a75d-841667135fbf",
   "metadata": {},
   "source": [
    "# check null values and remove null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99eb3739-cf10-4e4a-92fa-5ec38a887d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.notnull().sum()\n",
    "df = df.drop(['Unnamed: 2', 'Unnamed: 3','Unnamed: 4'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670235c1-4ace-496d-92f9-8172e61a23c7",
   "metadata": {},
   "source": [
    "# create column label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7c8e0a7-1467-42d3-adff-f3bf0a5497e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feedback                                             Review\n",
       "0         ham  Go until jurong point, crazy.. Available only ...\n",
       "1         ham                      Ok lar... Joking wif u oni...\n",
       "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         ham  U dun say so early hor... U c already then say...\n",
       "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...       ...                                                ...\n",
       "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568      ham              Will Ì_ b going to esplanade fr home?\n",
       "5569      ham  Pity, * was in mood for that. So...any other s...\n",
       "5570      ham  The guy did some bitching but I acted like i'd...\n",
       "5571      ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns=['feedback','Review']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359ced6e-391f-4002-b4b7-f1ed925cc390",
   "metadata": {},
   "source": [
    "# extract value from a dataset in the form of features matrix[X] $ traget matrix[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee0ce673-5bd3-470c-8713-a959f84eb62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.Review\n",
    "y=df.feedback\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05993bdb-104e-4e94-958d-2d34f4f72a99",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38a05da3-aeba-486f-b3d6-390c33a10ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wlen=WordNetLemmatizer()\n",
    "sw=stopwords.words('english')\n",
    "sw.remove('not')\n",
    "\n",
    "def text_cleaning(doc):\n",
    "        doc=doc.lower()\n",
    "        doc=re.sub(\"[^a-z]\",\" \",doc)\n",
    "        tokens=word_tokenize(doc)\n",
    "        new_doc=[]\n",
    "        for token in tokens:\n",
    "            token = wlen.lemmatize(token)  \n",
    "            if token in sw:\n",
    "                pass\n",
    "            else:\n",
    "                 new_doc.append(token)  \n",
    "    \n",
    "        return ' '.join(new_doc)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf246d45-1e2e-4f4f-b22a-c81ee349af75",
   "metadata": {},
   "source": [
    "#  split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f30db26c-f1de-4fa5-8569-f8d6144a5ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b894e24e-6fcf-48e0-a262-902c55fe2ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean=list(map(text_cleaning,X_train))\n",
    "X_test_clean=list(map(text_cleaning,X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ffe8e19-0224-435c-91b9-12303039d6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sore 0.9298875329026083\n",
      "test sore 0.8786791098348887\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "\n",
    "\n",
    "tv=TfidfVectorizer()\n",
    "X_new_matrix=tv.fit_transform(X_train_clean).toarray()\n",
    "X_test_matrix=tv.transform(X_test_clean).toarray()\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "model1=GaussianNB()\n",
    "model1.fit(X_new_matrix,y_train)\n",
    "\n",
    "print(\"train sore\",model1.score(X_new_matrix,y_train))\n",
    "print(\"test sore\",model1.score(X_test_matrix,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f971b29-6e2f-4f1d-9fca-10b4ebaafb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sore 0.9954534577650156\n",
      "test sore 0.9777458722182341\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "new_train=cv.fit_transform(X_train_clean)\n",
    "new_test=cv.transform(X_test_clean)\n",
    "model=LogisticRegression()\n",
    "model.fit(new_train,y_train)\n",
    "print(\"train sore\",model.score(new_train,y_train))\n",
    "print(\"test sore\",model.score(new_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d0fe83e-fae0-4426-8f7f-7f6b7dda17b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7a8bbec-92d4-4ed1-892d-f607923414a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spam_prediction_model']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model1,\"Spam_prediction_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb6f3782-c389-4b8c-93d8-4b30a8a285cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=joblib.load(\"Spam_prediction_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5755bd14-8bd8-4b81-9662-72c1c6a3754f",
   "metadata": {},
   "source": [
    "#  testing part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f0b2395-3700-4229-b3c1-82680daa9a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spam' 'spam' 'spam' 'spam']\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "test_cor=[\"WINNER!! As a valued network customer you have been selected to receivea å£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\",\n",
    "\"give your account details to get the offer\",\"you won a free trip of world tour\",\"Claim Your $1,000 Gift Card Now!\"]\t\t\n",
    "test_new=list(map(text_cleaning,test_cor))\n",
    "clean_test=tv.transform(test_new).toarray()\n",
    "print(model.predict(clean_test))\n",
    "print(model.predict_proba(clean_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9379e480-88ed-4770-ab7c-913a26610edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('you won a free trip of world tour', 'spam'),\n",
       " ('give your account details to get the offer', 'spam'),\n",
       " (\"Subject: Urgent! You've Won a $1,000 Gift Card!\", 'spam'),\n",
       " ('Claim Your $1,000 Gift Card Now!', 'spam'),\n",
       " ('hello sir,how are you?', 'spam'),\n",
       " ('congratulation,you got selected in final round of job process', 'ham'),\n",
       " ('you got selected as a lucky winner', 'spam')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file=pd.read_csv(\"d:/dataset/dataset/sentiment/test_data_spam.txt\",sep=('\\t'),header=None,names=['text'])\n",
    "test_file1=test_file['text']\n",
    "test_new=list(map(text_cleaning,test_file1))\n",
    "clean_test=tv.transform(test_new).toarray()\n",
    "predictions = model.predict(clean_test)\n",
    "pred1=[]\n",
    "for x,y in zip(test_file1,predictions):\n",
    "    pred1.append((x,y))\n",
    "pred1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42e8fb8-fe69-4abb-8ba1-54aaafa9093b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
